{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_leads = pd.read_csv(\"../Data/Raw/leads.csv\")\n",
    "raw_offers = pd.read_csv(\"../Data/Raw/offers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string \"nan\" into null values since they generated False Negatives values \n",
    "raw_leads.loc[raw_leads[\"Id\"] == \"nan\", \"Id\"] = np.nan\n",
    "raw_offers.loc[raw_offers[\"Id\"] == \"nan\", \"Id\"] = np.nan\n",
    "\n",
    "# Drop duplicated IDs\n",
    "raw_offers_no_duplicates = raw_offers.drop_duplicates(subset=[\"Id\"])\n",
    "\n",
    "# Creating a dataframe without null values on ID column\n",
    "leads_no_ID_nan = raw_leads[raw_leads[\"Id\"].notna()].copy()\n",
    "offers_no_ID_nan = raw_offers_no_duplicates[raw_offers_no_duplicates[\"Id\"].notna()].copy()\n",
    "\n",
    "# Filling the null data with a new category (Not_specified) \n",
    "leads_no_ID_nan.fillna(\"Not_Specified\", inplace=True)\n",
    "offers_no_ID_nan = offers_no_ID_nan.astype(str).replace('nan', 'Not_Specified')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df = leads_no_ID_nan\n",
    "offers_df = offers_no_ID_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the type of variable of dates fields\n",
    "offers_df[\"Created Date\"] = pd.to_datetime(offers_df[\"Created Date\"])\n",
    "offers_df[\"Close Date\"] = pd.to_datetime(offers_df[\"Close Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to know how many days took the sales process\n",
    "offers_df[\"Days\"] = offers_df[\"Close Date\"] - offers_df[\"Created Date\"]\n",
    "\n",
    "# Creating a column to know if there was applied a discount or not\n",
    "offers_df[\"Discount\"] = offers_df[\"Discount code\"] == \"Not_Specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the type of variable of dates fields for offers df\n",
    "offers_df[\"Created Date\"] = pd.to_datetime(offers_df[\"Created Date\"])\n",
    "offers_df[\"Close Date\"] = pd.to_datetime(offers_df[\"Close Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to know how many days took the sales process\n",
    "offers_df[\"Days\"] = offers_df[\"Close Date\"] - offers_df[\"Created Date\"]\n",
    "\n",
    "# Creating a column to know if there was applied a discount or not\n",
    "offers_df[\"Discount\"] = offers_df[\"Discount code\"] != \"Not_Specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unnecessary columns\n",
    "# \"Created Date\", \"Close Date\": already have a column to know how many days took the process\n",
    "# \"Discount code\": Already have a column that specified if a code was used or not (the specific code isnt relevant)\n",
    "# \"Loss Reason\": gives info of the target variable overfitting the model\n",
    "offers_reduced = offers_df.drop([\"Created Date\", \"Close Date\", \"Discount code\", \"Loss Reason\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the columns Use Case and Pain of offers df\n",
    "offers_encoded = pd.get_dummies(offers_reduced, columns=[\"Use Case\",\"Pain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the null values\n",
    "offers_encoded[\"Price\"] = offers_encoded[\"Price\"].replace({\"Not_Specified\": \"0\"})\n",
    "offers_encoded[\"Price\"] = offers_encoded[\"Price\"].astype(float).astype(int)\n",
    "\n",
    "# Creating columns to know the days that took the process\n",
    "offers_encoded[\"Days\"] = offers_encoded[\"Days\"].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the converted variable to bool\n",
    "leads_df.Converted = leads_df.Converted.astype('bool')\n",
    "\n",
    "# Removing some unnecessary columns for the algorythm like name or reason why was discarded \n",
    "# Discarded reason is a value that is given after know that the person was not converted it wont be an input for this model\n",
    "leads_reduced = leads_df.drop([\"First Name\", \"Discarded/Nurturing Reason\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode some leads DF variables\n",
    "leads_encoded = pd.get_dummies(leads_reduced, columns=[\"Use Case\",\"Source\"])\n",
    "\n",
    "# Aplying binary encoded\n",
    "# Initialize the encoder\n",
    "encoder = BinaryEncoder(cols=[\"Acquisition Campaign\", \"City\"])\n",
    "\n",
    "# Fit and transform the data\n",
    "leads_encoded = encoder.fit_transform(leads_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the date column into two columns, month and day to make it easier to process\n",
    "leads_encoded['Created Date'] = pd.to_datetime(leads_encoded['Created Date'])\n",
    "leads_encoded['month'] = leads_encoded['Created Date'].dt.month\n",
    "leads_encoded['day'] = leads_encoded['Created Date'].dt.day\n",
    "leads_encoded = leads_encoded.drop(['Created Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the dataframes\n",
    "merged = pd.merge(leads_encoded, offers_encoded, on=\"Id\")\n",
    "merged = merged[merged['Status_y'].isin(['Closed Lost', 'Closed Won'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and y variables\n",
    "X = merged.drop([\"Id\",\"Status_y\", \"Status_x\"], axis=1)\n",
    "y = merged[\"Status_y\"]\n",
    "\n",
    "# Creating training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.94%\n",
      "Cross-validation scores:  [0.82344428 0.81186686 0.82633864 0.81910275 0.77713459]\n",
      "Average cross-validation score:  0.8115774240231548\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "# Perform 5-fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# Print cross validation scores\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "\n",
    "# Print the average of the cross-validation scores\n",
    "print(\"Average cross-validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"../Data/Processed/final_single_enriched_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
