{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shimoku_api_python as shimoku\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.read_csv(\"../Data/Processed/merged_raw.csv\")\n",
    "raw_leads = pd.read_csv(\"../Data/Raw/leads.csv\")\n",
    "raw_offers = pd.read_csv(\"../Data/Raw/offers.csv\")\n",
    "merge_processed = pd.read_csv(\"../Data/Processed/merge_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:59 | INFO | Starting execution: \u001b[4mset_workspace\u001b[0m\n",
      "2023-12-15 09:59 | INFO | Finished execution: \u001b[4mset_workspace\u001b[0m, elapsed time: 2030.91 ms\n",
      "2023-12-15 09:59 | INFO | Starting execution: \u001b[4mset_menu_path\u001b[0m\n",
      "2023-12-15 09:59 | INFO | Retrieved menu path catalog with id 228ba832-394c-47e4-9a75-93431aea96c2\n",
      "2023-12-15 09:59 | INFO | Retrieved board Default Name with id bfebf856-afc6-4e02-bac1-c09e615f127c\n",
      "2023-12-15 09:59 | INFO | Finished execution: \u001b[4mset_menu_path\u001b[0m, elapsed time: 4709.83 ms\n"
     ]
    }
   ],
   "source": [
    "api_key: str = \"90336deb-e537-40a5-98e8-a91eb731a823\"\n",
    "universe_id: str = \"c2edae80-3e21-4f15-8c51-c394b34475cf\"\n",
    "workspace_id: str = \"e96f1077-ae84-4068-9333-457b5d65ec37\"\n",
    "\n",
    "\n",
    "s = shimoku.Client(\n",
    "    access_token=api_key,\n",
    "    universe_id=universe_id,\n",
    "    async_execution=True,\n",
    "    verbosity='INFO',\n",
    ")\n",
    "s.set_workspace(workspace_id)\n",
    "s.set_menu_path(\"catalog\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:59 | INFO | Starting execution: \u001b[4mclear_menu_path\u001b[0m\n",
      "2023-12-15 09:59 | INFO | Deleted 6 components\n",
      "2023-12-15 09:59 | INFO | Deleted 0 unused datasets from the menu path catalog\n",
      "2023-12-15 09:59 | INFO | Finished execution: \u001b[4mclear_menu_path\u001b[0m, elapsed time: 8424.65 ms\n"
     ]
    }
   ],
   "source": [
    "s.plt.clear_menu_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes to Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [{\"Cols\": list(raw_offers.isna().sum().index), \"Null Values\": list(raw_offers.isna().sum().values), \"Non-null Values\": list(raw_offers.shape[0] - value for value in raw_offers.isna().sum().values)}]\n",
    "data = pd.concat([pd.DataFrame(d) for d in data_list], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_list = [{\"Cols\": list(raw_leads.isna().sum().index), \"Null Values\": list(raw_leads.isna().sum().values), \"Non-null Values\": list(raw_leads.shape[0] - value for value in raw_leads.isna().sum().values)}]\n",
    "data2 = pd.concat([pd.DataFrame(d) for d in data2_list], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_list = [{\"Cols\": list(merge_df.isna().sum().index), \"Null Values\": list(merge_df.isna().sum().values), \"Non-null Values\": list(merge_df.shape[0] - value for value in merge_df.isna().sum().values)}]\n",
    "merge_data = pd.concat([pd.DataFrame(d) for d in merge_list], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:59 | INFO | html added to the task pool\n"
     ]
    }
   ],
   "source": [
    "prediction_header = (\n",
    "    \"<head>\"\n",
    "    \"<style>\"  # Styles title\n",
    "    \".component-title{height:auto; width:100%; \"\n",
    "    \"border-radius:16px; padding:16px;\"\n",
    "    \"display:flex; align-items:center;\"\n",
    "    \"background-color:var(--complementary-violet); color:var(--color-white);}\"\n",
    "    \"</style>\"\n",
    "    # Start icons style\n",
    "    \"<style>.big-icon-banner\"\n",
    "    \"{width:48px; height: 48px; display: flex;\"\n",
    "    \"margin-right: 16px;\"\n",
    "    \"justify-content: center;\"\n",
    "    \"align-items: center;\"\n",
    "    \"background-size: contain;\"\n",
    "    \"background-position: center;\"\n",
    "    \"background-repeat: no-repeat;\"\n",
    "    \"background-image: url('https://uploads-ssl.webflow.com/619f9fe98661d321dc3beec7/63594ccf3f311a98d72faff7_suite-customer-b.svg');}\"\n",
    "    \"</style>\"\n",
    "    # End icons style\n",
    "    \"<style>.base-white{color:var(--color-white);}</style>\"\n",
    "    \"</head>\"  # Styles subtitle\n",
    "    \"<div class='component-title'>\"\n",
    "    \"<div class='big-icon-banner'></div>\"\n",
    "    \"<div class='text-block'>\"\n",
    "    \"<h1>Thinking Process</h1>\"\n",
    "    \"<p class='base-white'>\"\n",
    "    \"And some considerations on the data and the problem by Alejandro Tovar</p>\"\n",
    "    \"</div>\"\n",
    "    \"</div>\"\n",
    ")\n",
    "s.plt.html(html=prediction_header, order=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mising Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:59 | INFO | html added to the task pool\n"
     ]
    }
   ],
   "source": [
    "distribution_header_html = (                                                                              \n",
    "    '<div style=\"width:100%; height:90px; \"><h3>Amount of Null Data for Each Dataset</h3>' \n",
    "    '''<p>Since there are some columns that have a high ratio of null data, I removed some columns (which didnt have an ID since those rows would be imposible to match between datasets),\n",
    "      and filled the values for other colums, with a categorical variable or a numerical one depending of each variable</p></div>'''\n",
    ")                                                                                                         \n",
    "s.plt.html(html=distribution_header_html, order=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:59 | INFO | stacked_horizontal_bar_chart added to the task pool\n"
     ]
    }
   ],
   "source": [
    "s.plt.stacked_horizontal_bar(\n",
    "    data=data, x=\"Cols\",\n",
    "    title='Number of Null Values for Offers',\n",
    "    order=2,\n",
    "    cols_size=6,\n",
    "    rows_size=3,\n",
    "    option_modifications={\"color\": [\"var(--color-error)\", \"var(--color-success-light)\"]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:59 | INFO | stacked_horizontal_bar_chart added to the task pool\n"
     ]
    }
   ],
   "source": [
    "s.plt.stacked_horizontal_bar(\n",
    "    data=data2, x=\"Cols\",\n",
    "    title='Number of Null Values for Leads',\n",
    "    order=3,\n",
    "    cols_size=6,\n",
    "    rows_size=3,\n",
    "    option_modifications={\"color\": [\"var(--color-error)\", \"var(--color-success-light)\"]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:59 | INFO | stacked_horizontal_bar_chart added to the task pool\n"
     ]
    }
   ],
   "source": [
    "s.plt.stacked_horizontal_bar(\n",
    "    data=merge_data, x=\"Cols\",\n",
    "    title='Number of Null values for the Merged Dataframe',\n",
    "    order=4,\n",
    "    cols_size=12,\n",
    "    option_modifications={\"color\": [\"var(--color-error)\", \"var(--color-success-light)\"]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:59 | INFO | html added to the task pool\n"
     ]
    }
   ],
   "source": [
    "distribution_header_html = (                                                                              \n",
    "    '<div style=\"width:100%; height:90px; \"><h3>Data Balance</h3>' \n",
    "    '''<p>The data is unbalanced for some specific features, Knowing this, I will be able to use a technique later to handle with this like resampling or SMOTE.</p></div>'''\n",
    ")                                                                                                         \n",
    "s.plt.html(html=distribution_header_html, order=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "Use_case_data = merge_df[\"Use Case_y\"].value_counts()\n",
    "Use_case_df = pd.DataFrame()\n",
    "Use_case_df[\"label\"] = Use_case_data.index \n",
    "Use_case_df[\"value\"] = Use_case_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pain_data = merge_df[\"Pain\"].value_counts()\n",
    "Pain_df = pd.DataFrame()\n",
    "Pain_df[\"label\"] = Pain_data.index\n",
    "Pain_df[\"value\"] = Pain_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:59 | INFO | pie_chart added to the task pool\n"
     ]
    }
   ],
   "source": [
    "s.plt.pie(\n",
    "    data=Use_case_df, \n",
    "    names=\"label\", \n",
    "    values=\"value\",\n",
    "    order=6, \n",
    "    rows_size=2, \n",
    "    cols_size=6,\n",
    "    title= \"Distribution of Use Case Data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 09:59 | INFO | pie_chart added to the task pool\n"
     ]
    }
   ],
   "source": [
    "s.plt.pie(\n",
    "    data=Pain_df, \n",
    "    names=\"label\", \n",
    "    values=\"value\",\n",
    "    order=7,\n",
    "    rows_size=2, \n",
    "    cols_size=6,\n",
    "    title= \"Distribution of Pain Data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 10:03 | INFO | html added to the task pool\n"
     ]
    }
   ],
   "source": [
    "distribution_header_html = (                                                                              \n",
    "    '<div style=\"width:100%; height:90px; \"><h3>Data Enrichment</h3>' \n",
    "    '''<p>In this step some correlation was checked and the data was encoded, One hot encoding was applied to features with few categories and binary encoded to\n",
    "     features with several categories.</p>\n",
    "     <p>Also some features were added and some unnecessary and data and low importance features were removed, as an example, the date columns where transformed to \n",
    "     days that take to close the deal that is more relevant data, there were a couple of columns with a very high correlation with the target variable and were remover also.</p></div>'''\n",
    ")                                                                                                         \n",
    "s.plt.html(html=distribution_header_html, order=8, rows_size=6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool      16\n",
       "int64     15\n",
       "object     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_processed.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 10:01 | INFO | Starting execution: \u001b[4mindicator\u001b[0m\n",
      "2023-12-15 10:01 | INFO | create indicator added to the task pool\n",
      "2023-12-15 10:01 | INFO | create indicator added to the task pool\n",
      "2023-12-15 10:01 | INFO | create indicator added to the task pool\n",
      "2023-12-15 10:01 | INFO | Finished execution: \u001b[4mindicator\u001b[0m, elapsed time: 10.56 ms\n",
      "2023-12-15 10:01 | INFO | Starting execution: \u001b[4mindicator\u001b[0m\n",
      "2023-12-15 10:01 | INFO | create indicator added to the task pool\n",
      "2023-12-15 10:01 | INFO | create indicator added to the task pool\n",
      "2023-12-15 10:01 | INFO | create indicator added to the task pool\n",
      "2023-12-15 10:01 | INFO | Finished execution: \u001b[4mindicator\u001b[0m, elapsed time: 9.89 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.plt.indicator(\n",
    "    order=9, cols_size=9,\n",
    "    padding=\"0,0,0,2\",\n",
    "    data=[\n",
    "         {\n",
    "             \"description\": \"Feature Engineering\",\n",
    "             \"title\": \"\",\n",
    "             \"value\": \"Before\",\n",
    "             \"align\": \"center\",\n",
    "             \"color\": \"default\",\n",
    "             \"variant\": \"contained\"\n",
    "        },\n",
    "        {\n",
    "             \"description\": \"\",\n",
    "             \"title\": \"Features\",\n",
    "             \"value\": merge_df.shape[1],\n",
    "             \"align\": \"center\",\n",
    "             \"color\": \"default\"\n",
    "        },\n",
    "        {\n",
    "            \"description\": \"object | int64 | float64\",\n",
    "            \"title\": \"data types\",\n",
    "            \"value\": \"16  |  1  |  1  \",\n",
    "            \"color\": \"default\",\n",
    "\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "s.plt.indicator(\n",
    "    order=12, cols_size=9,\n",
    "    padding=\"0,0,0,2\",\n",
    "    data=[\n",
    "         {\n",
    "             \"description\": \" Feature Engineering\",\n",
    "             \"title\": \"\",\n",
    "             \"value\": \"After\",\n",
    "             \"align\": \"center\",\n",
    "             \"color\": \"success\",\n",
    "             \"variant\": \"contained\"\n",
    "        },\n",
    "        {\n",
    "             \"description\": \"\",\n",
    "             \"title\": \"Features\",\n",
    "             \"value\": merge_processed.shape[1],\n",
    "             \"align\": \"center\",\n",
    "             \"color\": \"success\"\n",
    "        },\n",
    "        {\n",
    "            \"description\": \"object | int64 | bool\",\n",
    "            \"title\": \"data types\",\n",
    "            \"value\": \"2 | 15 | 16  \",\n",
    "            \"color\": \"success\",\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 10:03 | INFO | Executing task pool\n",
      "2023-12-15 10:03 | INFO | Starting execution: \u001b[4mhtml\u001b[0m\n",
      "2023-12-15 10:03 | INFO | Updated HTML at Test_8\n",
      "2023-12-15 10:03 | INFO | Finished execution: \u001b[4mhtml\u001b[0m, elapsed time: 2426.69 ms\n"
     ]
    }
   ],
   "source": [
    "s.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
